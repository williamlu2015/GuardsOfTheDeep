{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.data_loader import load_data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sys import maxsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[\n",
    "    df[\"starRating\"].notna()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1731)\n",
    "for train_indices, test_indices in kf.split(df_filtered):\n",
    "    df_train = df_filtered.iloc[train_indices, :]\n",
    "    df_test = df_filtered.iloc[test_indices, :]\n",
    "    \n",
    "    vectorizer = CountVectorizer(stop_words=None, ngram_range=(1, 1), min_df=1)\n",
    "    X_train = vectorizer.fit_transform(df_train[\"bodyText\"])\n",
    "    X_test = vectorizer.transform(df_test[\"bodyText\"])\n",
    "    \n",
    "    y_train = df_train[\"starRating\"].astype(int)\n",
    "    y_test = df_test[\"starRating\"].astype(int)\n",
    "    \n",
    "    classifier = RandomForestClassifier(\n",
    "        n_estimators=100, criterion=\"gini\", n_jobs=-1, random_state=1731, verbose=maxsize, class_weight=None\n",
    "    )\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4997238222993766,\n",
       " 0.4993292827270575,\n",
       " 0.48903093434343436,\n",
       " 0.5056029040404041,\n",
       " 0.4895833333333333]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.08057698\n",
      "Iteration 2, loss = 0.55313937\n",
      "Iteration 3, loss = 0.27400285\n",
      "Iteration 4, loss = 0.13132005\n",
      "Iteration 5, loss = 0.06009351\n",
      "Iteration 6, loss = 0.03443100\n",
      "Iteration 7, loss = 0.02449263\n",
      "Iteration 8, loss = 0.02498031\n",
      "Iteration 9, loss = 0.02757077\n",
      "Iteration 10, loss = 0.02541079\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.06117998\n",
      "Iteration 2, loss = 0.56193173\n",
      "Iteration 3, loss = 0.28279077\n",
      "Iteration 4, loss = 0.12037070\n",
      "Iteration 5, loss = 0.04991012\n",
      "Iteration 6, loss = 0.02983878\n",
      "Iteration 7, loss = 0.02346298\n",
      "Iteration 8, loss = 0.02203106\n",
      "Iteration 9, loss = 0.02347802\n",
      "Iteration 10, loss = 0.02170192\n",
      "Iteration 11, loss = 0.02545230\n",
      "Iteration 12, loss = 0.03853238\n",
      "Iteration 13, loss = 0.03648917\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.05590665\n",
      "Iteration 2, loss = 0.54832545\n",
      "Iteration 3, loss = 0.25931748\n",
      "Iteration 4, loss = 0.10526127\n",
      "Iteration 5, loss = 0.04529398\n",
      "Iteration 6, loss = 0.02728773\n",
      "Iteration 7, loss = 0.02320544\n",
      "Iteration 8, loss = 0.02781284\n",
      "Iteration 9, loss = 0.02041922\n",
      "Iteration 10, loss = 0.02302308\n",
      "Iteration 11, loss = 0.02426887\n",
      "Iteration 12, loss = 0.02484125\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.06883133\n",
      "Iteration 2, loss = 0.54089972\n",
      "Iteration 3, loss = 0.24715479\n",
      "Iteration 4, loss = 0.09319584\n",
      "Iteration 5, loss = 0.03836956\n",
      "Iteration 6, loss = 0.02409516\n",
      "Iteration 7, loss = 0.02160980\n",
      "Iteration 8, loss = 0.02208191\n",
      "Iteration 9, loss = 0.02053429\n",
      "Iteration 10, loss = 0.02236735\n",
      "Iteration 11, loss = 0.03838426\n",
      "Iteration 12, loss = 0.04410903\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.07172926\n",
      "Iteration 2, loss = 0.53736723\n",
      "Iteration 3, loss = 0.25412951\n",
      "Iteration 4, loss = 0.10104712\n",
      "Iteration 5, loss = 0.04295678\n",
      "Iteration 6, loss = 0.02863178\n",
      "Iteration 7, loss = 0.02790646\n",
      "Iteration 8, loss = 0.03145667\n",
      "Iteration 9, loss = 0.02844976\n",
      "Iteration 10, loss = 0.02568696\n",
      "Iteration 11, loss = 0.02359630\n",
      "Iteration 12, loss = 0.02225419\n",
      "Iteration 13, loss = 0.02265551\n",
      "Iteration 14, loss = 0.02194757\n",
      "Iteration 15, loss = 0.02451084\n",
      "Iteration 16, loss = 0.03155504\n",
      "Iteration 17, loss = 0.03348740\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "mlp_accuracies = []\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1731)\n",
    "for train_indices, test_indices in kf.split(df_filtered):\n",
    "    df_train = df_filtered.iloc[train_indices, :]\n",
    "    df_test = df_filtered.iloc[test_indices, :]\n",
    "    \n",
    "    vectorizer = CountVectorizer(stop_words=None, ngram_range=(1, 1), min_df=1)\n",
    "    X_train = vectorizer.fit_transform(df_train[\"bodyText\"])\n",
    "    X_test = vectorizer.transform(df_test[\"bodyText\"])\n",
    "    \n",
    "    y_train = df_train[\"starRating\"].astype(int)\n",
    "    y_test = df_test[\"starRating\"].astype(int)\n",
    "    \n",
    "    classifier = MLPClassifier(random_state=1731, verbose=True)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    mlp_accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5432020831689418,\n",
       " 0.5455693206028565,\n",
       " 0.5272253787878788,\n",
       " 0.5403251262626263,\n",
       " 0.5294349747474747]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
